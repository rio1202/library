import requests
import psycopg2
from tqdm import tqdm
from pyquery import PyQuery
from urllib.parse import urlparse
import fitz
from gpt4all import GPT4All
from datetime import datetime
import json
import re
import os
import time
import logging

DB_CONFIG = {
    "dbname": "book_scraper",
    "user": "postgres",
    "password": "root",
    "host": "localhost",
    "port": "5432",
}

max_books = 15  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
batch_size = 15  # –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
LOG_FILE = "parser.log"  # –§–∞–π–ª –¥–ª—è –ª–æ–≥–æ–≤

MODEL_NAME = "orca-mini-3b.gguf" # –ú–æ–¥—É–ª—å –ª–æ–∫–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ AI

MODEL_PATH = os.path.expanduser("~/.cache/gpt4all/")


logging.basicConfig(
    filename=LOG_FILE,
    filemode="a",
    format="%(asctime)s [%(levelname)s] %(message)s",
    level=logging.INFO
)

# –î—É–±–ª–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –≤ –∫–æ–Ω—Å–æ–ª—å –∏ –≤ –ª–æ–≥-—Ñ–∞–π–ª
def log(msg):
    print(msg)
    logging.info(msg)


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –Ω–µ–π –º–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–∞—Ä—Å–∏–ª —Å —Å–∞–π—Ç–∞ –∏ –¥–∞–Ω–Ω—ã–µ ..._parsed, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –ø–∞—Ä—Å–∏—Ç—å AI, –¥–∞–ª–µ–µ —è —Ö–æ—Ç–µ–ª —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ù–æ –Ω–∞–¥–æ –≤—Ä–µ–º—è, —á—Ç–æ–±—ã —ç—Ç–æ –≤—Å–µ –¥–æ–¥–µ–ª–∞—Ç—å.
def init_database():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    cursor.execute("DROP TABLE IF EXISTS books")
    cursor.execute("""CREATE TABLE books
                      (
                          id                 SERIAL PRIMARY KEY,  
                          book_title         TEXT,                
                          book_author        TEXT,                
                          book_link          TEXT UNIQUE,         
                          book_body          BYTEA,               
                          book_downloaded    BOOLEAN   DEFAULT FALSE, 
                          book_title_parsed  TEXT,                
                          book_author_parsed TEXT,                
                          book_year_parsed   TEXT,                
                          created_at         TIMESTAMP DEFAULT NOW() 
                      )""")
    conn.commit()
    conn.close()
    log("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

# –ü–∞—Ä—Å–∏–Ω–≥ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–Ω–∏–≥ —Å —Å–∞–π—Ç–∞
def parse_book_metadata(max_books):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    book_counter = 0
    page_num = 2  # –°—Ç–∞—Ä—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 2, —Ç.–∫. –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ Json –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –≤—Å–µ—Ö –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º data[]

    try:
        while book_counter < max_books:
            try:
                response = requests.get(
                    f"https://www.mann-ivanov-ferber.ru/catalog/?apimode=1&page={page_num}",
                    timeout=15
                )
                response.raise_for_status()
            except (requests.exceptions.RequestException, requests.exceptions.Timeout) as e:
                log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                time.sleep(5)
                continue

            try:
                data = response.json()
            except json.JSONDecodeError:
                log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
                page_num += 1
                continue

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–Ω–∏–≥
            books = data.get("products", [])

            if not books:
                log("‚ÑπÔ∏è –ë–æ–ª—å—à–µ –∫–Ω–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                break

            for book in books:
                if book_counter >= max_books:
                    break

                book_title = book.get("title", "").strip()
                book_author = book.get("author_name", "").strip()
                book_url = book.get("url", "")

                if not book_title or not book_url:
                    continue

                try:
                    page = requests.get(book_url, timeout=15)
                    pq = PyQuery(page.text)

                    pdf_element = pq('a:contains("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∫–Ω–∏–≥–∏"), a:contains("–ß–∏—Ç–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç")')
                    pdf_path = pdf_element.attr("href")

                    if not pdf_path:
                        log(f"‚ÑπÔ∏è –î–ª—è –∫–Ω–∏–≥–∏ '{book_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω PDF")
                        continue

                    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ URL PDF
                    parsed_url = urlparse(book_url)
                    pdf_link = f"{parsed_url.scheme}://{parsed_url.netloc}{pdf_path}"

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å—Å—ã–ª–∫–∏ –≤ –ë–î
                    cursor.execute("SELECT id FROM books WHERE book_link = %s", (pdf_link,))
                    if cursor.fetchone():
                        continue

                    cursor.execute("""INSERT INTO books (book_title, book_author, book_link)
                                      VALUES (%s, %s, %s)""",
                                   (book_title, book_author, pdf_link))
                    conn.commit()

                    book_counter += 1
                    log(f"üìö –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–Ω–∏–≥–∞: {book_title} [{book_counter}/{max_books}]")

                except Exception as e:
                    conn.rollback()
                    log(f"‚ùå –û—à–∏–±–∫–∞ –∫–Ω–∏–≥–∏ '{book_title}': {e}")
                    continue

            page_num += 1
            time.sleep(1)

    except Exception as e:
        log(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ parse_book_metadata: {e}")
    finally:
        conn.close()
        log(f"‚úÖ –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω. –î–æ–±–∞–≤–ª–µ–Ω–æ: {book_counter} –∫–Ω–∏–≥")


# –∫–∞—á–∞–µ–º –ø–¥—Ñ –≤ –ë–î
def download_pdfs(batch_size):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    try:

        cursor.execute("""SELECT id, book_title, book_link
                          FROM books
                          WHERE book_downloaded = FALSE
                              LIMIT %s""", (batch_size,))

        books = cursor.fetchall()

        # –∫—Ä–∞—Å–∏–≤—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä.
        for book_id, title, link in tqdm(books, desc="‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF"):
            try:
                response = requests.get(link, timeout=30)
                response.raise_for_status()

                if not response.headers.get('Content-Type', '').lower().startswith('application/pdf'):
                    log(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è PDF: {link}")

                    cursor.execute("""UPDATE books SET book_downloaded = TRUE WHERE id = %s""", (book_id,))
                    conn.commit()
                    continue

                pdf = response.content
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ë–î
                cursor.execute("""UPDATE books SET book_body = %s, book_downloaded = TRUE WHERE id = %s""",(psycopg2.Binary(pdf), book_id))
                conn.commit()
                log(f"‚úÖ PDF —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {title}")

            except Exception as e:
                conn.rollback()
                log(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è '{title}': {e}")
            time.sleep(1)

    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –≤ download_pdfs: {e}")
    finally:
        conn.close()

# –ü–∞—Ä—Å–∏–Ω–≥ PDF —Å –ø–æ–º–æ—â—å—é GPT4All. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø–æ–∫–∞ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏. –≤–æ–∑–º–æ–∂–Ω–æ –Ω–∞–¥–æ –±—Ä–∞—Ç—å –ø–ª–∞—Ç–Ω—ã–µ –≤–µ—Ä—Å–∏–∏.
# –í –î–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –∫–∞—á–∞–ª –ª–æ–∫–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é GPT4All. –Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–Ω–∞ –Ω–µ –∑–∞—Ä–∞–±–æ—Ç–∞–ª–∞.
def parse_pdf_with_gpt4all(pdf_bytes, original_title="", original_author="", model=None):
    try:

        if model is None:
            model = GPT4All(model_name=MODEL_NAME, model_path=MODEL_PATH, device='cpu')

        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            text = ""
            for page in doc:
                text += page.get_text()
                if len(text) > 3000:
                    break

        prompt = (
            f"–í–æ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥–∏:\n\n{text[:3000]}\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–≤–ª–µ–∫–∏:\n"
            "- –ù–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏\n"
            "- –ò–º—è –∞–≤—Ç–æ—Ä–∞\n"
            "- –ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n"
            "–§–æ—Ä–º–∞—Ç: JSON —Å –ø–æ–ª—è–º–∏ title, author, year"
        )

        response = model.generate(prompt=prompt, max_tokens=512)

        # –ü–æ–∏—Å–∫ JSON –≤ –æ—Ç–≤–µ—Ç–µ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        try:
            match = re.search(r'\{[\s\S]*\}', response)
            if match:
                parsed = json.loads(match.group())
            else:
                parsed = {}
        except json.JSONDecodeError:
            parsed = {}

        return {
            "title": parsed.get("title", original_title),
            "author": parsed.get("author", original_author),
            "year": parsed.get("year", "")
        }

    except Exception as e:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥
        log(f"‚ùå GPT4All –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å PDF: {e}")
        return parse_pdf_metadata_locally(pdf_bytes, original_title, original_author)

# –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–¥—Ñ —Å –ø–æ–º–æ—â—å—é –ò–ò
def parse_pdfs_with_local_analyzer(batch_size):
    conn = psycopg2.connect(**DB_CONFIG)  # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    cursor = conn.cursor()

    try:

        cursor.execute("""SELECT id, book_title, book_author, book_body
                          FROM books
                          WHERE book_downloaded = TRUE
                            AND book_title_parsed IS NULL
                              LIMIT %s""", (batch_size,))

        books = cursor.fetchall()

        model = GPT4All(model_name=MODEL_NAME, model_path=MODEL_PATH, device='cpu')

        for book_id, title, author, pdf in tqdm(books, desc="üß† GPT4All –ø–∞—Ä—Å–∏–Ω–≥ PDF"):
            try:
                parsed = parse_pdf_with_gpt4all(pdf, title, author, model)

                cursor.execute("""UPDATE books
                                  SET book_title_parsed  = %s,
                                      book_author_parsed = %s,
                                      book_year_parsed   = %s
                                  WHERE id = %s""",
                               (parsed['title'], parsed['author'], parsed['year'], book_id))
                conn.commit()
                log(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {title}")
            except Exception as e:
                conn.rollback()
                log(f"‚ùå –û—à–∏–±–∫–∞ GPT4All '{title}': {e}")
            time.sleep(1)

    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –≤ parse_pdfs_with_local_analyzer: {e}")
    finally:
        if 'model' in locals():
            del model
        conn.close()

# –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥, –µ—Å–ª–∏ AI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç
def parse_pdf_metadata_locally(pdf_content, original_title="", original_author=""):
    try:
        doc = fitz.open(stream=pdf_content, filetype="pdf")
        metadata = doc.metadata or {}
        title = metadata.get("title", "").strip() or original_title
        author = metadata.get("author", "").strip() or original_author
        creation_date = metadata.get("creationDate", "")
        year = creation_date[2:6] if creation_date and creation_date.startswith("D:") else ""

        return {"title": title, "author": author, "year": year}

    except Exception as e:
        # –í–æ–∑–≤—Ä–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏ –æ—à–∏–±–∫–µ
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        return {"title": original_title, "author": original_author, "year": ""}


def main():

    log("\n" + "=" * 50)
    log(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    log("=" * 50 + "\n")

    try:
        init_database()
        parse_book_metadata(max_books)
        download_pdfs(batch_size=10)
        parse_pdfs_with_local_analyzer(batch_size=10)
    except Exception as e:
        log(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ main: {e}")
    finally:
        log("\n" + "=" * 50)
        log(f"üèÅ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("=" * 50 + "\n")


if __name__ == "__main__":
    main() #1